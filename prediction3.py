"""
SAM2 Video Predictor + Full 3D Visualization
(Pose Estimation + LiDAR Segmentation + Plane Mesh)
"""

import os
import sys
import csv
import copy
import traceback
import re
import glob
import joblib
import numpy as np
import torch
import cv2
import open3d as o3d
import matplotlib.pyplot as plt
from PIL import Image
from matplotlib.patches import Polygon
from scipy.optimize import least_squares

# ========================================
# 1. í™˜ê²½ ì„¤ì •
# ========================================
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

# SAM2 ê²½ë¡œ ì„¤ì •
SAM2_ROOT = "/workspace/sam2"
if SAM2_ROOT not in sys.path:
    sys.path.insert(0, SAM2_ROOT)

# ========================================
# 2. ë””ë°”ì´ìŠ¤ ì„¤ì •
# ========================================
def setup_device():
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… Using CUDA: {torch.cuda.get_device_name(0)}")
        torch.autocast("cuda", dtype=torch.bfloat16).__enter__()
        if torch.cuda.get_device_properties(0).major >= 8:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âš ï¸  Using MPS (preliminary support)")
    else:
        device = torch.device("cpu")
        print("â„¹ï¸  Using CPU")
    return device

device = setup_device()

# ========================================
# 3. SAM2 ëª¨ë¸ ë¡œë“œ
# ========================================
try:
    from sam2.build_sam import build_sam2_video_predictor
    print("âœ… SAM2 module imported")
except ImportError as e:
    print(f"âŒ SAM2 import failed: {e}")
    sys.exit(1)

sam2_checkpoint = "/workspace/sam2/sam2.1_hiera_large.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
predictor = build_sam2_video_predictor(model_cfg, sam2_checkpoint, device=device)

# ========================================
# 4. ê²½ë¡œ ë° íŒŒë¼ë¯¸í„° ì„¤ì •
# ========================================
class Config:
    ID = "202511250901568327"
    BASE_DIR = f"/workspace/sequences_sample/{ID}"
    VIDEO_DIR = f"{BASE_DIR}/image"
    PCD_DIR = f"{BASE_DIR}/pcd"
    RESULTS_DIR = f"{BASE_DIR}/results"
    INTRINSIC_PATH = "/workspace/sam2/intrinsic.csv"
    EXTRINSIC_PATH = "/workspace/sam2/transform3_tuned_tuned.txt"
    OUTPUT_DIR = f"./frame_out_full_vis/{ID}"
    
    REVERSED = True
    
    # Obj1 í”„ë¡¬í”„íŠ¸: DZ ê¸°ë°˜ ìë™ ìƒì„± (ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸)
    OBJ_1_POINTS = None  # Will be auto-generated from DZ
    OBJ_1_LABELS = np.array([1, 1, 0], dtype=np.int32)  # 3 positive prompts
    
    # Obj2 í”„ë¡¬í”„íŠ¸ (ê³ ì •)
    if not REVERSED :
        OBJ_2_POINTS = np.array([[820, 270], [820, 800]], dtype=np.float32)
        OBJ_2_LABELS = np.array([1, 1], dtype=np.int32)
    else :
        OBJ_2_POINTS = np.array([[830, 490], [830, 670]], dtype=np.float32)
        OBJ_2_LABELS = np.array([1, 1], dtype=np.int32)
    
    
    APPLY_EROSION = True
    EROSION_KERNEL_SIZE = 9
    EROSION_ITERATIONS = 3
    MAX_DEPTH = 15.0
    SHOW_O3D = False

    ACWL_DZ = None  # Will be loaded from results
    DEPTH_TH = None  # Will be calculated from ACWL_DZ

os.makedirs(Config.OUTPUT_DIR, exist_ok=True)

# ========================================
# 5. í”„ë¡¬í”„íŠ¸ ì˜ˆì¸¡ í•¨ìˆ˜ (ML Model ê¸°ë°˜)
# ========================================
MODEL_PATH = "./annotation/model_prompt.pkl"
N_POINTS_OBJ2 = 4  # OBJ_2 í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ (2~4)

# ë¡œê·¸ íŒŒì‹± ì •ê·œì‹
DZ_PATTERN = re.compile(r"DZ Distance\s*:\s*(\d+)\s*mm")
WIDTH_PATTERN = re.compile(r"Plate Max Width\s*:\s*(\d+)\s*mm")
TOPLEN_PATTERN = re.compile(r"Plate Top Length\s*:\s*(\d+)\s*mm")

def parse_txt_full(path):
    """ê²°ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ DZ, Width, Length íŒŒì‹±"""
    with open(path, "r", encoding="utf-8") as f:
        t = f.read()
    dz_match = DZ_PATTERN.search(t)
    w_match = WIDTH_PATTERN.search(t)
    L_match = TOPLEN_PATTERN.search(t)
    
    if not dz_match or not w_match or not L_match:
        return None, None, None
    
    dz = int(dz_match.group(1))
    w = int(w_match.group(1))
    L = int(L_match.group(1))
    return dz, w, L

def predict_obj2_prompts(schedule_id, n_points=N_POINTS_OBJ2):
    """
    ML ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ OBJ_2 í”„ë¡¬í”„íŠ¸ ìë™ ì˜ˆì¸¡
    
    Args:
        schedule_id: ìŠ¤ì¼€ì¤„ ID
        n_points: ìƒì„±í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ (2~4)
    
    Returns:
        prompts: np.ndarray (n_points, 2) ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    if not (2 <= n_points <= 4):
        print(f"   âš ï¸ n_pointsëŠ” 2~4 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ê°’: {n_points}")
        return None
    
    # ëª¨ë¸ ë¡œë“œ
    if not os.path.exists(MODEL_PATH):
        print(f"   âš ï¸ ML ëª¨ë¸ íŒŒì¼ ì—†ìŒ: {MODEL_PATH}")
        return None
    
    try:
        model = joblib.load(MODEL_PATH)
    except Exception as e:
        print(f"   âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    # Results ë””ë ‰í† ë¦¬ì—ì„œ ì²« ë²ˆì§¸ txt íŒŒì¼ ì°¾ê¸°
    base_dir = f"/workspace/sequences_sample/{schedule_id}"
    results_dir = os.path.join(base_dir, "results")
    
    if not os.path.exists(results_dir):
        print(f"   âš ï¸ Results ë””ë ‰í† ë¦¬ ì—†ìŒ: {results_dir}")
        return None
    
    txts = sorted(glob.glob(os.path.join(results_dir, "*.txt")))
    if not txts:
        print(f"   âš ï¸ Results txt íŒŒì¼ ì—†ìŒ: {results_dir}")
        return None
    
    txt_path = txts[0]
    dz, w, L = parse_txt_full(txt_path)
    
    if dz is None or w is None or L is None:
        print(f"   âš ï¸ DZ/Width/Length íŒŒì‹± ì‹¤íŒ¨: {txt_path}")
        return None
    
    # ML ëª¨ë¸ë¡œ ê° í¬ì¸íŠ¸ ì˜ˆì¸¡
    prompts = []
    for point_idx in range(1, n_points + 1):
        X_in = np.array([[dz, w, L, point_idx]], dtype=float)
        try:
            u_pred, v_pred = model.predict(X_in)[0]
            prompts.append([int(round(u_pred)), int(round(v_pred))])
        except Exception as e:
            print(f"   âš ï¸ Point {point_idx} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return None
    
    return np.array(prompts, dtype=np.float32)

# ========================================
# 6. ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ (DZ ê¸°ë°˜ - OBJ_1ìš©)
# ========================================
def get_prompt_points_from_dz(dz: float):
    """
    DZ(mm)ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ í¬ì¸íŠ¸ë¥¼ ìë™ ê²°ì •.
    - dz = 2346 â†’ [(1020,400), (1020,740), (1020,570)]
    - dz = 673  â†’ [(1010,450), (1010,710), (1010,580)]
    - ë²”ìœ„ ë°–ë„ clamp ì—†ì´ ê·¸ëŒ€ë¡œ ì„ í˜• ì™¸ì‚½
    
    Returns:
        points: np.ndarray (3,2)
    """
    # Anchor values
    dz_far  = 2346
    pts_far = np.array([[1020, 400],
                        [1020, 740],
                        [1020, 570]], dtype=np.float32)

    dz_near = 673
    pts_near = np.array([[1010, 450],
                         [1010, 710],
                         [1010, 580]], dtype=np.float32)

    # t=0 â†’ near, t=1 â†’ far (ë²”ìœ„ ë°–ë„ ê·¸ëŒ€ë¡œ ì™¸ì‚½)
    t = (dz - dz_near) / float(dz_far - dz_near)

    # Linear interpolation (extrapolation allowed)
    pts = (1.0 - t) * pts_near + t * pts_far

    return pts.astype(np.float32)

def parse_dz_from_results(results_dir, frame_idx=0):
    """
    Parse DZ Distance value from results text file
    
    Args:
        results_dir: Path to results directory
        frame_idx: Frame index to find corresponding result file
    
    Returns:
        dz_value: DZ Distance in mm, or None if not found
    """
    if not os.path.exists(results_dir):
        return None
    
    # Get all txt files sorted
    txt_files = sorted([f for f in os.listdir(results_dir) if f.endswith('.txt')])
    
    if frame_idx >= len(txt_files):
        return None
    
    txt_path = os.path.join(results_dir, txt_files[frame_idx])
    
    try:
        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # Search for "DZ Distance" line using regex
        match = re.search(r'DZ Distance\s*:\s*(\d+)\s*mm', content)
        
        if match:
            dz_value = int(match.group(1))
            print(f"   ğŸ“„ Found DZ Distance: {dz_value}mm")
            return dz_value
        else:
            print(f"   âš ï¸ DZ Distance not found in {txt_files[frame_idx]}")
            return None
            
    except Exception as e:
        print(f"   âŒ Error reading {txt_path}: {e}")
        return None

# ========================================
# 7. ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ë¡œë“œ
# ========================================
def load_camera_params(intrinsic_path, extrinsic_path):
    intrinsic = np.loadtxt(intrinsic_path, delimiter=',', usecols=range(9))
    K = np.array([
        [intrinsic[0], intrinsic[1], intrinsic[2]],
        [0.0,          intrinsic[3], intrinsic[4]],
        [0.0,          0.0,          1.0]
    ], dtype=np.float32)
    D = np.array([intrinsic[5], intrinsic[6], intrinsic[7], intrinsic[8]], dtype=np.float32)
    T_l2c = np.loadtxt(extrinsic_path, delimiter=',').astype(np.float32)
    print(f"âœ… Camera parameters loaded")
    return K, D, T_l2c

K_camera, D_dist, T_l2c = load_camera_params(Config.INTRINSIC_PATH, Config.EXTRINSIC_PATH)

# ========================================
# 6. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ë§ˆìŠ¤í¬ ì²˜ë¦¬)
# ========================================
# ... (show_mask, apply_erosion, to_bool_mask, clamp_inside í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) ...
def show_mask(mask, ax, obj_id=None, random_color=False):
    """ë§ˆìŠ¤í¬ ì‹œê°í™”"""
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        cmap = plt.get_cmap("tab10")
        cmap_idx = 0 if obj_id is None else obj_id
        color = np.array([*cmap(cmap_idx)[:3], 0.6])
    
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)

def apply_erosion(mask_bool, kernel_size=5, iterations=1):
    """ë§ˆìŠ¤í¬ì— erosion ì ìš©í•˜ì—¬ ê²½ê³„ë¥¼ ì¶•ì†Œ"""
    mask_uint8 = mask_bool.astype(np.uint8) * 255
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    eroded = cv2.erode(mask_uint8, kernel, iterations=iterations)
    dialated = cv2.dilate(eroded, kernel, iterations=iterations)
    return dialated > 0

def to_bool_mask(mask_np):
    """ë§ˆìŠ¤í¬ë¥¼ boolean ë°°ì—´ë¡œ ë³€í™˜"""
    if mask_np.ndim > 2:
        mask_np = mask_np.squeeze()
    return mask_np.astype(bool)

def mask_to_rotated_box(mask_bool):
    """ë§ˆìŠ¤í¬ì—ì„œ íšŒì „ ë°•ìŠ¤ ë° ìƒ/í•˜/ì¢Œ/ìš° ì¢Œí‘œ ë°˜í™˜"""
    ys, xs = np.where(mask_bool)
    if ys.size == 0:
        return None, None, None, None, None, None, None, None, None, None, None
    
    pts = np.stack([xs, ys], axis=1).astype(np.float32)
    rect = cv2.minAreaRect(pts)
    (cxm, cym), (w, h), ang = rect
    
    angle_deg = (ang + 90.0) % 180.0 if w < h else (ang % 180.0)
    corners = cv2.boxPoints(rect).astype(np.float32)
    
    # AABB
    xmin, xmax = xs.min(), xs.max()
    ymin, ymax = ys.min(), ys.max()
    mid_y = (ymin + ymax) / 2.0
    
    # ì¢Œí‘œ ì¶”ì¶œ
    top_cx = float(cxm); top_y = float(ymin)
    bottom_cx = float(cxm); bottom_y = float(ymax)
    left_x = float(xmin); left_y = float(mid_y)
    right_x = float(xmax); right_y = float(mid_y)
    
    return corners, angle_deg, (xmin, ymin, xmax, ymax), top_cx, top_y, bottom_cx, bottom_y, left_x, left_y, right_x, right_y

def draw_mask_and_rbox(ax, mask_bool, oid, edge_color, H, W, apply_erosion_flag=True, erosion_kernel=5, erosion_iter=1):
    """ë§ˆìŠ¤í¬ì™€ íšŒì „ ë°•ìŠ¤ ê·¸ë¦¬ê¸° ë° ì¢Œí‘œ ë°˜í™˜"""
    show_mask(mask_bool, ax, obj_id=oid)
    
    mask_for_box = apply_erosion(mask_bool, kernel_size=erosion_kernel, iterations=erosion_iter) if apply_erosion_flag else mask_bool
    
    corners, angle_deg, aabb, top_cx, top_y, bottom_cx, bottom_y, left_x, left_y, right_x, right_y = mask_to_rotated_box(mask_for_box)
    
    if corners is None:
        return None, None, None, None, None, None, None, None
    
    poly = Polygon(corners, closed=True, fill=False, linewidth=2, edgecolor=edge_color)
    ax.add_patch(poly)
    
    return top_y, top_cx, bottom_y, bottom_cx, left_y, left_x, right_y, right_x



# ========================================
# 7. Pose Estimation Logic (Model & Functions)
# ========================================

# Magnet Model Dimensions (Meters)
MAGNET_WIDTH = 0.45
MAGNET_LENGTH = 2.25
MAGNET_HEIGHT = 0.191

# 3D ëª¨ë¸ í¬ì¸íŠ¸ (ìƒë‹¨ ë©´)
model_points_2d = np.array([
    [0.0, 0.0],           # Point 0: TL
    [0.0, MAGNET_LENGTH],   # Point 1: BL
    [MAGNET_WIDTH, MAGNET_LENGTH], # Point 2: BR
    [MAGNET_WIDTH, 0.0]     # Point 3: TR
], dtype=np.float32)

model_points_3d_top = np.hstack([model_points_2d, np.zeros((4, 1))])

def affine_matrix(param):
    """2D Affine ë³€í™˜ í–‰ë ¬ (XY í‰ë©´ ì´ë™/íšŒì „)"""
    tx, ty, theta = param[:3]
    cos_t = np.cos(theta)
    sin_t = np.sin(theta)
    M = np.array([
        [cos_t, -sin_t, tx],
        [sin_t,  cos_t, ty],
        [0,      0,      1]
    ], dtype=float)
    return M

def transform_points_3d(param, points_local_3d):
    """ë¡œì»¬ 3D ì ë“¤ì„ ì›”ë“œ(ì¹´ë©”ë¼ ì˜¤í”„ì…‹ ê¸°ì¤€) ì¢Œí‘œë¡œ ë³€í™˜"""
    pose_mat = affine_matrix(param)
    Z_global = param[3]
    
    pts_xy = points_local_3d[:, :2]
    pts_xy_aug = np.hstack([pts_xy, np.ones((pts_xy.shape[0], 1))])
    pts_transformed_xy = (pose_mat @ pts_xy_aug.T).T
    
    pts_transformed = np.zeros_like(points_local_3d)
    pts_transformed[:, 0] = pts_transformed_xy[:, 0]
    pts_transformed[:, 1] = pts_transformed_xy[:, 1]
    pts_transformed[:, 2] = points_local_3d[:, 2] + Z_global 
    
    return pts_transformed

def projection(param, model_points, intrinsic, distortion):
    """íŒŒë¼ë¯¸í„° -> 3D ë³€í™˜ -> 2D íˆ¬ì˜"""
    object_points_world = transform_points_3d(param, model_points)

    rvec = np.zeros((3, 1), dtype=np.float32)
    tvec = np.array([[0], [0], [5.0]], dtype=np.float32) # ê³ ì • ì˜¤í”„ì…‹ 5.0m

    image_points, _ = cv2.projectPoints(
        object_points_world, rvec, tvec, intrinsic, distortion
    )
    return image_points.reshape(-1, 2)

def cost_function(param, model_points, corner_point, intrinsic, distortion):
    predicted = projection(param, model_points, intrinsic, distortion)
    return (corner_point.astype(np.float64) - predicted).ravel()

def order_points_for_model(pts):
    """
    ê²€ì¶œëœ 4ê°œ ì½”ë„ˆì ì„ ëª¨ë¸ ì •ì˜ ìˆœì„œ(TL, BL, BR, TR)ì™€ ì¼ì¹˜í•˜ë„ë¡ ì •ë ¬
    """
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)] # TL (sum min)
    rect[2] = pts[np.argmax(s)] # BR (sum max)
    
    diff = np.diff(pts, axis=1)
    rect[3] = pts[np.argmin(diff)] # TR (diff = y-x. xê°€ í¬ë¯€ë¡œ diff min)
    rect[1] = pts[np.argmax(diff)] # BL (diff = y-x. yê°€ í¼)
    
    return rect



def filter_points_by_mask(points_3d_cam, mask, K, D, W, H, depth_threshold=None, depth_range=0.1, update_mask=False):
    """
    3D í¬ì¸íŠ¸(Camera Frame) ì¤‘ 2D ë§ˆìŠ¤í¬ ë‚´ë¶€ì— ìœ„ì¹˜í•œ í¬ì¸íŠ¸ë§Œ í•„í„°ë§
    
    Args:
        points_3d_cam: 3D í¬ì¸íŠ¸ (N, 3)
        mask: 2D ë§ˆìŠ¤í¬ (H, W)
        K, D: ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°
        W, H: ì´ë¯¸ì§€ í¬ê¸°
        depth_threshold: Zê°’ ì„ê³„ê°’. ì´ ê°’ë³´ë‹¤ í° ì ë“¤ì€ í•„í„°ë§ë¨
        update_mask: Trueì´ë©´ threshold ì´ˆê³¼ í¬ì¸íŠ¸ì˜ ë§ˆìŠ¤í¬ í”½ì…€ì„ Falseë¡œ ì—…ë°ì´íŠ¸
    
    Returns:
        filtered_points: í•„í„°ë§ëœ 3D í¬ì¸íŠ¸
        updated_mask: update_mask=Trueì¼ ë•Œ ì—…ë°ì´íŠ¸ëœ ë§ˆìŠ¤í¬, ì•„ë‹ˆë©´ None
    """
    if len(points_3d_cam) == 0 or mask is None:
        return (np.array([]), mask.copy() if update_mask else None) if update_mask else np.array([])

    # 1. 3D -> 2D íˆ¬ì˜ (ì™œê³¡ ë³´ì • í¬í•¨)
    # rvec, tvecëŠ” 0 (ì´ë¯¸ Camera Frameì´ë¯€ë¡œ)
    img_pts, _ = cv2.projectPoints(points_3d_cam, np.zeros(3), np.zeros(3), K, D)
    img_pts = img_pts.squeeze() # (N, 2)

    # 2. ì´ë¯¸ì§€ ë²”ìœ„ ì²´í¬
    u = img_pts[:, 0]
    v = img_pts[:, 1]
    
    # ì¢Œí‘œê°€ ì´ë¯¸ì§€ ë²”ìœ„ ì•ˆì¸ì§€ í™•ì¸
    valid_uv = (u >= 0) & (u < W) & (v >= 0) & (v < H)
    
    # 3. Depth threshold ì²´í¬ (ì˜µì…˜)
    if depth_threshold is not None:
        depth_min = depth_threshold - depth_range
        depth_max = depth_threshold + 0.25
        depth_valid = (points_3d_cam[:, 2] >= depth_min) & (points_3d_cam[:, 2] <= depth_max)
    else:
        depth_valid = np.ones(len(points_3d_cam), dtype=bool)
    
    # 4. ë§ˆìŠ¤í¬ í™•ì¸
    # valid_uvì™€ depth_validê°€ Trueì¸ ì¸ë±ìŠ¤ì— ëŒ€í•´ì„œë§Œ ë§ˆìŠ¤í¬ ê°’ ì¡°íšŒ (ì •ìˆ˜ ë³€í™˜)
    combined_valid = valid_uv & depth_valid
    u_valid = u[combined_valid].astype(int)
    v_valid = v[combined_valid].astype(int)
    
    # ë§ˆìŠ¤í¬ê°€ 1(True)ì¸ í”½ì…€ì¸ì§€ í™•ì¸
    in_mask = mask[v_valid, u_valid]
    
    # combined_valid í†µê³¼í•œ ì• ë“¤ ì¤‘ì—ì„œë„ in_maskì¸ ì• ë“¤ì˜ ì›ë˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    # 1) combined_valid ì¸ë±ìŠ¤ ì¶”ì¶œ
    indices_in_bounds = np.where(combined_valid)[0]
    # 2) ê·¸ ì¤‘ì—ì„œ mask í†µê³¼í•œ ì¸ë±ìŠ¤
    final_indices = indices_in_bounds[in_mask]
    
    # 5. ë§ˆìŠ¤í¬ ì—…ë°ì´íŠ¸ (ì˜µì…˜)
    updated_mask = None
    if update_mask:
        updated_mask = mask.copy()
        # Depth threshold ì´ˆê³¼ í¬ì¸íŠ¸ë“¤ì˜ ë§ˆìŠ¤í¬ í”½ì…€ì„ Falseë¡œ ì„¤ì •
        if depth_threshold is not None:
            invalid_depth_indices = np.where(valid_uv & ~depth_valid)[0]
            u_invalid = u[invalid_depth_indices].astype(int)
            v_invalid = v[invalid_depth_indices].astype(int)
            # ë²”ìœ„ ì²´í¬ í›„ ë§ˆìŠ¤í¬ ì—…ë°ì´íŠ¸
            valid_coords = (u_invalid >= 0) & (u_invalid < W) & (v_invalid >= 0) & (v_invalid < H)
            u_invalid = u_invalid[valid_coords]
            v_invalid = v_invalid[valid_coords]
            updated_mask[v_invalid, u_invalid] = False
    
    if update_mask:
        return points_3d_cam[final_indices], updated_mask
    else:
        return points_3d_cam[final_indices]



def refine_pose_icp_constrained(source_bottom_points, target_plane_points, max_iteration=30):
    """
    [ìˆ˜ì •ë¨] Roll(ì¢Œìš°) + Pitch(ì•ë’¤) íšŒì „ ë° Zì¶• ì´ë™ í—ˆìš©.
    Yaw(ì œìë¦¬ íšŒì „)ëŠ” ì°¨ë‹¨.
    íšŒì „ ì‹œ ë°œìƒí•˜ëŠ” ê·¸ë„¤ íš¨ê³¼(Lever Arm Effect)ë¥¼ ë³´ì •í•˜ì—¬ ì¤‘ì‹¬ì  ìœ ì§€.
    """
    # 1. Sourceì˜ ì¤‘ì‹¬ì  ê³„ì‚° (íšŒì „ì˜ ê¸°ì¤€ì )
    centroid_source = np.mean(source_bottom_points, axis=0)

    source = o3d.geometry.PointCloud()
    source.points = o3d.utility.Vector3dVector(source_bottom_points)
    
    target = o3d.geometry.PointCloud()
    target.points = o3d.utility.Vector3dVector(target_plane_points)
    
    # ë²•ì„  ê³„ì‚°
    search_radius = 0.1
    target.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamRadius(radius=search_radius))
    source.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamRadius(radius=search_radius))
    
    # 2. ì¼ë°˜ ICP ìˆ˜í–‰
    threshold = 0.3
    T_init = np.identity(4)
    
    reg = o3d.pipelines.registration.registration_icp(
        source, target, threshold, T_init,
        o3d.pipelines.registration.TransformationEstimationPointToPlane(),
        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iteration)
    )
    
    T_full = reg.transformation
    
    # 3. íšŒì „ ì„±ë¶„ ë¶„í•´ ë° Roll, Pitch ì¶”ì¶œ
    R = T_full[:3, :3]
    t_icp = T_full[:3, 3]
    
    sy = np.sqrt(R[0,0]**2 + R[1,0]**2)
    if sy > 1e-6:
        roll = np.arctan2(R[2,1], R[2,2])
        pitch = np.arctan2(-R[2,0], sy) # Pitch ê°’ ì¶”ì¶œ
        # yaw = np.arctan2(R[1,0], R[0,0]) # YawëŠ” ë¬´ì‹œ
    else:
        roll = np.arctan2(-R[1,2], R[1,1])
        pitch = np.arctan2(-R[2,0], sy)
        # yaw = 0

    # 4. ì œì•½ëœ íšŒì „ í–‰ë ¬ ì¬êµ¬ì„± (Roll + Pitch)
    # Rx (Roll)
    c_r, s_r = np.cos(roll), np.sin(roll)
    Rx = np.array([
        [1, 0, 0],
        [0, c_r, -s_r],
        [0, s_r, c_r]
    ])
    
    # Ry (Pitch) - ìƒˆë¡œ ì¶”ê°€ë¨
    c_p, s_p = np.cos(pitch), np.sin(pitch)
    Ry = np.array([
        [c_p, 0, s_p],
        [0, 1, 0],
        [-s_p, 0, c_p]
    ])
    
    # ê²°í•©ëœ íšŒì „ í–‰ë ¬ (R_new = Ry @ Rx)
    # ìˆœì„œëŠ” ë¯¸ì„¸í•œ ì°¨ì´ê°€ ìˆì§€ë§Œ ë³´í†µ Pitch -> Roll ìˆœì´ë‚˜ ê·¸ ë°˜ëŒ€ë‚˜
    # í‰ë©´ ì •ë ¬ìš© ë¯¸ì„¸ ê°ë„ì—ì„œëŠ” í° ì°¨ì´ ì—†ìŒ. ì—¬ê¸°ì„  Ry @ Rx ì ìš©.
    R_constrained = Ry @ Rx
    
    # 5. [í•µì‹¬] ì¤‘ì‹¬ì  ë³´ì • (Centroid Compensation)
    # ëª©í‘œ ì¤‘ì‹¬ì : X, YëŠ” ìœ ì§€(Obj1 ì›ë˜ ìœ„ì¹˜), ZëŠ” ICPê°€ ì œì•ˆí•œ ì´ë™ëŸ‰ ë°˜ì˜
    target_centroid = centroid_source.copy()
    target_centroid[2] += t_icp[2] 
    
    # íšŒì „ë§Œ ì ìš©í–ˆì„ ë•Œ ì¤‘ì‹¬ì ì´ ì–´ë””ë¡œ íŠ€ëŠ”ì§€ ê³„ì‚°
    rotated_centroid = R_constrained @ centroid_source
    
    # ê·¸ ì°¨ì´ë§Œí¼ì„ Translationìœ¼ë¡œ ì„¤ì •í•˜ì—¬ X,Y ìœ„ì¹˜ë¥¼ ê³ ì •
    t_compensated = target_centroid - rotated_centroid
    
    # ìµœì¢… ë³€í™˜ í–‰ë ¬ ì¡°ë¦½
    T_constrained = np.identity(4)
    T_constrained[:3, :3] = R_constrained
    T_constrained[:3, 3] = t_compensated
    
    # ë””ë²„ê¹… ì¶œë ¥
    print(f"   âš–ï¸ Constrained ICP: Roll={np.degrees(roll):.2f}Â°, Pitch={np.degrees(pitch):.2f}Â°, dZ={t_icp[2]:.3f}m")
    
    return T_constrained

# ========================================
# 9. 3D ì‹œê°í™” í•¨ìˆ˜ (Open3D)
# ========================================
def get_3d_box_mesh(param, color=[1, 0, 0]):
    """
    ì¶”ì •ëœ íŒŒë¼ë¯¸í„°ë¡œ 3D ë°•ìŠ¤ ë©”ì‰¬ (Solid)ì™€ ì™€ì´ì–´í”„ë ˆì„ (LineSet)ì„ ìƒì„±í•˜ì—¬ ë°˜í™˜
    """
    
    top_face = model_points_3d_top 
    bottom_face = top_face.copy()
    bottom_face[:, 2] += MAGNET_HEIGHT 
    local_box_points = np.vstack([top_face, bottom_face])
    
    world_points = transform_points_3d(param, local_box_points)
    camera_points = world_points + np.array([0, 0, 5.0]) # tvec=[0,0,5] ì ìš©
    
    vertices = camera_points
    
    # 1. Solid Mesh ìƒì„±
    triangles = np.array([
        [0, 1, 2], [0, 2, 3], # Top Face
        [4, 6, 5], [4, 7, 6], # Bottom Face
        [0, 3, 7], [0, 7, 4], # Side 1
        [3, 2, 6], [3, 6, 7], # Side 2
        [2, 1, 5], [2, 5, 6], # Side 3
        [1, 0, 4], [1, 4, 5]  # Side 4
    ])
    
    mesh = o3d.geometry.TriangleMesh()
    mesh.vertices = o3d.utility.Vector3dVector(vertices)
    mesh.triangles = o3d.utility.Vector3iVector(triangles)
    mesh.compute_vertex_normals()
    mesh.paint_uniform_color(color)
    
    # 2. Wireframe (LineSet) ìƒì„±
    wireframe = o3d.geometry.LineSet.create_from_triangle_mesh(mesh)
    wireframe.paint_uniform_color([0, 0, 0]) # ê²€ì€ìƒ‰ ì™¸ê³½ì„ 
    
    # [ìˆ˜ì •] Meshì™€ Wireframe ë‘ ê°ì²´ë¥¼ ë°˜í™˜
    return mesh, wireframe


def show_geometries_with_backface(geoms, title="Viewer"):
    vis = o3d.visualization.Visualizer()
    vis.create_window(window_name=title, width=1280, height=720)
    for g in geoms:
        vis.add_geometry(g)
    opt = vis.get_render_option()
    opt.mesh_show_back_face = True   # ë’·ë©´ë„ ë Œë”ë§
    vis.run()
    vis.destroy_window()


def two_stage_plane_fit(points_3d, dist_thresh1=0.10, dist_thresh2=0.03, min_inlier_ratio=0.3, min_inlier_abs=30, max_iterations=5):
    """
    Iterative í‰ë©´ í”¼íŒ… (outlier ì œê±°ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰)
    
    Parameters:
    - points_3d: ì…ë ¥ 3D ì êµ°
    - dist_thresh1: 1ì°¨ í”¼íŒ… ê±°ë¦¬ ì„ê³„ê°’
    - dist_thresh2: 2ì°¨ ì´í›„ í”¼íŒ… ê±°ë¦¬ ì„ê³„ê°’
    - min_inlier_abs: ìµœì†Œ inlier ê°œìˆ˜
    - max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    
    Returns:
    - normal: í‰ë©´ ë²•ì„  ë²¡í„°
    - d: í‰ë©´ ë°©ì •ì‹ ê³„ìˆ˜ (ax + by + cz + d = 0)
    - centroid: í‰ë©´ ì¤‘ì‹¬ì 
    - inlier_mask: ìµœì¢… inlier ë§ˆìŠ¤í¬
    """
    pts = np.asarray(points_3d, dtype=np.float64)
    N = pts.shape[0]
    if N < 3: 
        return None, None, None, None

    # 1ì°¨ í”¼íŒ… (ì´ˆê¸° outlier ì œê±°)
    centroid = pts.mean(axis=0)
    pts_centered = pts - centroid
    _, _, vh = np.linalg.svd(pts_centered, full_matrices=False)
    normal = vh[-1]
    normal = normal / (np.linalg.norm(normal) + 1e-12)
    dist = np.abs((pts - centroid) @ normal)
    inlier_mask = dist < dist_thresh1
    
    if inlier_mask.sum() < min_inlier_abs:
        return normal, -float(np.dot(normal, centroid)), centroid, inlier_mask

    # Iterative refinement
    prev_inlier_count = inlier_mask.sum()
    
    for iteration in range(max_iterations):
        pts_inliers = pts[inlier_mask]
        
        if pts_inliers.shape[0] < 3:
            break
        
        # í˜„ì¬ inlierë“¤ë¡œ í‰ë©´ ì¬í”¼íŒ…
        centroid = pts_inliers.mean(axis=0)
        pts_centered = pts_inliers - centroid
        _, _, vh = np.linalg.svd(pts_centered, full_matrices=False)
        normal = vh[-1]
        normal = normal / (np.linalg.norm(normal) + 1e-12)
        
        # ì „ì²´ ì ë“¤ì— ëŒ€í•´ ê±°ë¦¬ ì¬ê³„ì‚°
        dist = np.abs((pts - centroid) @ normal)
        new_inlier_mask = dist < dist_thresh2
        
        if new_inlier_mask.sum() < min_inlier_abs:
            break
        
        # ìˆ˜ë ´ ì²´í¬: inlier ê°œìˆ˜ê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ
        current_inlier_count = new_inlier_mask.sum()
        if current_inlier_count == prev_inlier_count:
            print(f"   ğŸ”„ Plane fitting converged at iteration {iteration + 1}")
            break
        
        # RMS ê±°ë¦¬ ê³„ì‚° (ë””ë²„ê¹…ìš©)
        rms_dist = np.sqrt(np.mean(dist[new_inlier_mask]**2))
        print(f"   ğŸ”„ Iteration {iteration + 1}: Inliers={current_inlier_count}/{N}, RMS={rms_dist:.4f}m")
        
        inlier_mask = new_inlier_mask
        prev_inlier_count = current_inlier_count
    
    # ìµœì¢… í‰ë©´ ë°©ì •ì‹ ê³„ìˆ˜
    d = -float(np.dot(normal, centroid))
    
    return normal, d, centroid, inlier_mask

def build_rbox_clipped_plane(
    rbox_corners, normal, centroid, K, dist_coeffs, color=(0.0, 0.3, 0.5)
):
    """íšŒì „ ë°•ìŠ¤ í¬ê¸°ë§Œí¼ ì˜ë¦° í‰ë©´ ë©”ì‰¬ ìƒì„± (ì™œê³¡ ë³´ì • ì ìš©)"""
    if rbox_corners is None: return None
    uv_pts = np.asarray(rbox_corners, dtype=np.float32).reshape(-1, 1, 2)
    if uv_pts.shape[0] < 3: return None

    # ì™œê³¡ ì œê±° -> ì •ê·œí™”ëœ ì¢Œí‘œê³„ë¡œ ë³€í™˜
    xy_undistorted = cv2.undistortPoints(uv_pts, K, dist_coeffs).squeeze()
    
    n = np.asarray(normal, dtype=np.float32); n = n / (np.linalg.norm(n) + 1e-12)
    p0 = np.asarray(centroid, dtype=np.float32)

    verts = []
    for x_n, y_n in xy_undistorted:
        d_ray = np.array([x_n, y_n, 1.0], dtype=np.float32)
        d_ray = d_ray / np.linalg.norm(d_ray)
        denom = float(np.dot(n, d_ray))
        
        if abs(denom) < 1e-6: continue
        t = float(np.dot(n, p0) / denom)
        if t <= 0: continue

        P = d_ray * t
        verts.append(P)

    if len(verts) < 3: return None
    verts = np.array(verts, dtype=np.float64); Kp = verts.shape[0]

    triangles = []
    for i in range(1, Kp - 1): triangles.append([0, i, i + 1])
    triangles = np.array(triangles, dtype=np.int32)

    mesh = o3d.geometry.TriangleMesh()
    mesh.vertices = o3d.utility.Vector3dVector(verts)
    mesh.triangles = o3d.utility.Vector3iVector(triangles)
    mesh.compute_vertex_normals()
    mesh.paint_uniform_color(color)

    return mesh


def generate_synthetic_plane_cloud(corners_2d, normal, centroid, K, D, density=0.02):
    """
    Obj2ì˜ 2D ì½”ë„ˆì™€ í‰ë©´ íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•´ 3D ê³µê°„ ìƒì˜ ì¡°ë°€í•œ í‰ë©´ ì êµ° ìƒì„±
    density: ì  ê°„ê²© (ë¯¸í„° ë‹¨ìœ„)
    """
    if corners_2d is None or normal is None:
        return None

    # 1. 2D ì½”ë„ˆë¥¼ Undistort (ì™œê³¡ ë³´ì •)
    uv_pts = np.asarray(corners_2d, dtype=np.float32).reshape(-1, 1, 2)
    xy_undistorted = cv2.undistortPoints(uv_pts, K, D).squeeze()

    # 2. í‰ë©´ íŒŒë¼ë¯¸í„° ì¤€ë¹„
    n = np.asarray(normal, dtype=np.float32)
    n = n / (np.linalg.norm(n) + 1e-12)
    p0 = np.asarray(centroid, dtype=np.float32)

    # 3. 4ê°œì˜ 3D ì½”ë„ˆì  ê³„ì‚° (Raycasting)
    corners_3d = []
    for x_n, y_n in xy_undistorted:
        d_ray = np.array([x_n, y_n, 1.0], dtype=np.float32)
        d_ray = d_ray / np.linalg.norm(d_ray) # ë‹¨ìœ„ ë²¡í„°
        
        denom = float(np.dot(n, d_ray))
        if abs(denom) < 1e-6: continue # ì‹œì„ ê³¼ í‰ë©´ì´ í‰í–‰í•¨
        
        t = float(np.dot(n, p0) / denom)
        if t <= 0: continue # í‰ë©´ì´ ì¹´ë©”ë¼ ë’¤ì— ìˆìŒ
        
        P = d_ray * t
        corners_3d.append(P)
        
    if len(corners_3d) < 3: return None
    corners_3d = np.array(corners_3d)

    # 4. 4ê°œ ì  ë‚´ë¶€ë¥¼ ì±„ìš°ëŠ” ê·¸ë¦¬ë“œ ìƒì„± (Bilinear Interpolation or Meshgrid)
    # ê°„ë‹¨í•˜ê²Œ AABBë¥¼ êµ¬í•´ì„œ ê·¸ë¦¬ë“œë¥¼ ë§Œë“¤ê³  í‰ë©´ ë°©ì •ì‹ìœ¼ë¡œ Z íˆ¬ì˜
    min_xyz = corners_3d.min(axis=0)
    max_xyz = corners_3d.max(axis=0)
    
    x_range = np.arange(min_xyz[0], max_xyz[0], density)
    y_range = np.arange(min_xyz[1], max_xyz[1], density)
    
    # í‰ë©´ ë°©ì •ì‹: nx*x + ny*y + nz*z = dot(n, p0) -> z = (dot(n,p0) - nx*x - ny*y) / nz
    d_plane = np.dot(n, p0)
    
    synthetic_points = []
    if abs(n[2]) > 1e-6: # Zì¶• ì„±ë¶„ì´ ìˆì„ ë•Œë§Œ (ìˆ˜ì§ í‰ë©´ ì•„ë‹˜)
        xv, yv = np.meshgrid(x_range, y_range)
        xv = xv.flatten()
        yv = yv.flatten()
        zv = (d_plane - n[0]*xv - n[1]*yv) / n[2]
        
        # ìƒì„±ëœ ì ë“¤ì´ 4ê°í˜• ì•ˆì— ìˆëŠ”ì§€ ì²´í¬í•  ìˆ˜ë„ ìˆì§€ë§Œ, ICPìš©ì´ë¯€ë¡œ AABB ì „ì²´ ì‚¬ìš©í•´ë„ ë¬´ë°©
        synthetic_points = np.vstack([xv, yv, zv]).T
    else:
        # ìˆ˜ì§ í‰ë©´ì¸ ê²½ìš° ì˜ˆì™¸ì²˜ë¦¬ (ì—¬ê¸°ì„  ìƒëµí•˜ê±°ë‚˜ ì›ë³¸ ì½”ë„ˆë§Œ ì‚¬ìš©)
        return corners_3d

    return np.array(synthetic_points, dtype=np.float32)

def get_obj1_bottom_cloud(pose_param):
    """
    Obj1ì˜ í˜„ì¬ Poseë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°”ë‹¥ë©´ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„± (Source for ICP)
    """
    # ëª¨ë¸ì˜ ë°”ë‹¥ë©´ ì •ì˜ (Topì—ì„œ Zì¶•ìœ¼ë¡œ ë†’ì´ë§Œí¼ ë‚´ë¦¼)
    # ì¢€ ë” ì¡°ë°€í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ grid ìƒì„±
    X, Y = np.meshgrid(np.linspace(0, MAGNET_WIDTH, 20), np.linspace(0, MAGNET_LENGTH, 20))
    local_bottom = np.vstack([X.ravel(), Y.ravel(), np.full_like(X.ravel(), MAGNET_HEIGHT)]).T
    
    # World ë³€í™˜ -> Camera Frame ë³€í™˜
    P_world = transform_points_3d(pose_param, local_bottom)
    P_camera = P_world + np.array([0, 0, 5.0]) # Offset ì ìš©
    
    return P_camera

def calculate_length_measurements(magnet_pose, slab_corners_3d):
    """
    ICP ì •í•©ì´ ì™„ë£Œëœ ë§ˆê·¸ë„· Poseì™€ ì² íŒ ì½”ë„ˆë¥¼ ì´ìš©í•˜ì—¬ ì§€ì •ëœ ê¸¸ì´ ì¸¡ì •
    
    Args:
        magnet_pose (np.array): ë§ˆê·¸ë„·ì˜ 6-DoF íŒŒë¼ë¯¸í„° [tx, ty, tz, rx, ry, rz]
        slab_corners_3d (np.array): ì² íŒ(Obj2)ì˜ 3D ì½”ë„ˆì  4ê°œ (ìˆœì„œ: TL, BL, BR, TR)
        
    Returns:
        len_top (float): ìœ„ìª½ 700mm ì§€ì  ì¸¡ì • ê±°ë¦¬ (mm)
        len_bot (float): ì•„ë˜ìª½ 700mm ì§€ì  ì¸¡ì • ê±°ë¦¬ (mm)
    """
    # 1. ë§ˆê·¸ë„· ë’·ë©´(Right Edge) ì •ì˜ (Local ì¢Œí‘œê³„)
    # ë§ˆê·¸ë„· ëª¨ë¸: Xì¶•(í­)=0.45, Yì¶•(ê¸¸ì´)=2.25
    # ê·¸ë¦¼ìƒ "ë’·ë©´"ì€ ê¸´ ë³€ ì¤‘ í•˜ë‚˜ì„.
    # ë§ˆê·¸ë„· ì¤‘ì‹¬ì„ ê¸°ì¤€ìœ¼ë¡œ ì¢Œí‘œë¥¼ ìƒê°í•˜ë©´ ë” ì‰½ì§€ë§Œ, í˜„ì¬ ëª¨ë¸ì€ Top-Left(0,0) ê¸°ì¤€ì„.
    # ê°€ì •: ë§ˆê·¸ë„·ì´ ì„¸ë¡œë¡œ ê¸´ ìƒíƒœ(2.25m)ë¼ë©´, 700mmëŠ” ì–‘ ë(0.0ê³¼ 2.25)ì—ì„œ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¨ ê²ƒ.
    
    # ë§ˆê·¸ë„· ë¡œì»¬ ì¢Œí‘œ (ë‹¨ìœ„: m)
    # ê¸°ì¤€ë³€(Back Face): X=0.45 (ì˜¤ë¥¸ìª½ ë³€) ì´ë¼ê³  ê°€ì • (ì¢Œí‘œê³„ í™•ì¸ í•„ìš”)
    # ìœ„ìª½ ì¸¡ì •ì  (P1): X=0.45, Y = 0.7 (700mm)
    # ì•„ë˜ìª½ ì¸¡ì •ì  (P2): X=0.45, Y = 2.25 - 0.7 (1.55m)
    # ì¸¡ì • ë°©í–¥ (Normal): Xì¶• ì–‘ì˜ ë°©í–¥ (1, 0, 0) -> ê·¸ë¦¼ìƒ ì˜¤ë¥¸ìª½ í™”ì‚´í‘œ
    
    local_p1 = np.array([MAGNET_WIDTH, 0.7, 0.0])
    local_p2 = np.array([MAGNET_WIDTH, MAGNET_LENGTH - 0.7, 0.0])
    
    # ë°©í–¥ ë²¡í„° (ë¡œì»¬ Xì¶• ë°©í–¥)
    local_direction = np.array([1.0, 0.0, 0.0]) 

    # 2. ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜ (Pose ì ìš©)
    # transform_points_3d í•¨ìˆ˜ëŠ” (N,3) ì…ë ¥ì„ ë°›ìŒ
    p1_world = transform_points_3d(magnet_pose, local_p1.reshape(1, 3)).flatten()
    p2_world = transform_points_3d(magnet_pose, local_p2.reshape(1, 3)).flatten()
    
    # ë°©í–¥ ë²¡í„° íšŒì „ (ìœ„ì¹˜ ì´ë™ì€ ì œì™¸í•˜ê³  íšŒì „ë§Œ ì ìš©)
    R_mat, _ = cv2.Rodrigues(magnet_pose[3:]) # Rotation Matrix
    dir_world = R_mat @ local_direction
    dir_world = dir_world / np.linalg.norm(dir_world) # ì •ê·œí™”
    
    # Zì¶• ë¬´ì‹œí•˜ê³  2D í‰ë©´(XY)ì—ì„œ ê³„ì‚° (Top View)
    start_pt_1 = p1_world[:2]
    start_pt_2 = p2_world[:2]
    measure_dir = dir_world[:2]
    measure_dir /= np.linalg.norm(measure_dir) # 2D ì •ê·œí™”

    # 3. ì² íŒì˜ íƒ€ê²Ÿ ë³€(Target Edge) ì°¾ê¸°
    # ì² íŒ ì½”ë„ˆ 4ê°œ ì¤‘ ì¸¡ì • ë°©í–¥ê³¼ êµì°¨í•  ìˆ˜ ìˆëŠ” 'ì˜¤ë¥¸ìª½ ë³€'ì„ ì°¾ì•„ì•¼ í•¨.
    # ê°„ë‹¨íˆ: ì² íŒ ì¤‘ì‹¬ ê¸°ì¤€ìœ¼ë¡œ ì¸¡ì • ë°©í–¥ ìª½ì— ìˆëŠ” ë‘ ì ì„ ì´ì€ ì„ ë¶„
    
    slab_center = np.mean(slab_corners_3d[:, :2], axis=0)
    # ê° ì½”ë„ˆê°€ ì¤‘ì‹¬ì—ì„œ ì–´ëŠ ë°©í–¥ì¸ì§€ ë‚´ì  ê³„ì‚°
    # (ì½”ë„ˆ - ì¤‘ì‹¬) dot (ì¸¡ì •ë°©í–¥) ê°’ì´ ê°€ì¥ í° ë‘ ì ì´ Target Edgeì„
    
    dots = np.dot(slab_corners_3d[:, :2] - slab_center, measure_dir)
    target_idx = np.argsort(dots)[-2:] # ê°€ì¥ í° ê°’ 2ê°œ ì¸ë±ìŠ¤
    
    edge_p1 = slab_corners_3d[target_idx[0], :2]
    edge_p2 = slab_corners_3d[target_idx[1], :2]
    
    # 4. ì§ì„  êµì°¨ì  ê³„ì‚° (Line-Line Intersection)
    def get_distance_to_line(start_pt, direction, line_p1, line_p2):
        # Ray: P = start + t * dir
        # Line: Q = p1 + u * (p2 - p1)
        # êµì°¨ì  ì°¾ê¸° (2D)
        x1, y1 = start_pt
        dx, dy = direction
        x3, y3 = line_p1
        x4, y4 = line_p2
        
        # í‰í–‰ ê²€ì‚¬ (ë¶„ëª¨)
        denom = dx * (y3 - y4) - dy * (x3 - x4)
        if abs(denom) < 1e-6: return 0.0 # í‰í–‰ (êµì°¨ ì•ˆí•¨)
        
        # t ê³„ì‚° (Rayì—ì„œì˜ ê±°ë¦¬)
        t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom
        
        return t # ë¯¸í„° ë‹¨ìœ„ ê±°ë¦¬

    len_top = get_distance_to_line(start_pt_1, measure_dir, edge_p1, edge_p2)
    len_bot = get_distance_to_line(start_pt_2, measure_dir, edge_p1, edge_p2)
    
    # ê²°ê³¼ ë°˜í™˜ (mm ë‹¨ìœ„ ë³€í™˜, ì ˆëŒ€ê°’)
    return abs(len_top * 1000), abs(len_bot * 1000), (start_pt_1, start_pt_2, measure_dir)

def calculate_width_measurement(magnet_pose, slab_corners_3d):
    """
    ë§ˆê·¸ë„· ìœ„ìª½ ì•ˆìª½ ì½”ë„ˆì—ì„œ ì² íŒ ìœ—ë³€ê¹Œì§€ì˜ ìˆ˜ì§ ê±°ë¦¬ë¥¼ ì¸¡ì • (ë¶€í˜¸ í¬í•¨)
    """
    # 1. ë§ˆê·¸ë„· ê¸°ì¤€ì  (Measure Point) ì •ì˜ - ë¡œì»¬ ì¢Œí‘œê³„
    # ëª¨ë¸ ì •ì˜: TL(0,0), BL(0, 2.25), BR(0.45, 2.25), TR(0.45, 0)
    # ê·¸ë¦¼ìƒ 'ìœ„ìª½ ì•ˆìª½ ì½”ë„ˆ'ëŠ” TL(0,0) ë˜ëŠ” TR(0.45, 0) ì¤‘ í•˜ë‚˜ì„.
    # ê·¸ë¦¼ì˜ 'ë§ˆê·¸ë„· ë’·ë©´'ì´ ì˜¤ë¥¸ìª½ ë³€(BR-TR)ì´ë¼ë©´, 'ì•ˆìª½'ì€ ì™¼ìª½ ë³€(TL-BL)ì„.
    # ë”°ë¼ì„œ 'ìœ„ìª½ ì•ˆìª½ ì½”ë„ˆ'ëŠ” **TL (0, 0)** ì§€ì ìœ¼ë¡œ ì¶”ì •ë¨.
    
    local_measure_pt = np.array([0.0, 0.0, 0.0]) 
    
    # 2. ì¸¡ì • ë°©í–¥ (Normal Vector) ì •ì˜ - ë¡œì»¬ ì¢Œí‘œê³„
    # ë§ˆê·¸ë„· ìœ—ë³€(Top Edge)ì— ìˆ˜ì§ì¸ ë°©í–¥.
    # ëª¨ë¸ìƒ ìœ—ë³€ì€ Y=0 ë¼ì¸. ìˆ˜ì§ì¸ ë°”ê¹¥ ë°©í–¥ì€ **Yì¶• ìŒì˜ ë°©í–¥ (0, -1, 0)**
    # (ì´ë¯¸ì§€ ì¢Œí‘œê³„ìƒ ìœ„ìª½ì´ Yê°ì†Œ ë°©í–¥ì´ë¼ë©´ -1, ì•„ë‹ˆë¼ë©´ ì¢Œí‘œê³„ í™•ì¸ í•„ìš”)
    
    local_direction = np.array([0.0, -1.0, 0.0]) 

    # 3. ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜ (Pose ì ìš©)
    # ì  ë³€í™˜
    p_measure_world = transform_points_3d(magnet_pose, local_measure_pt.reshape(1, 3)).flatten()
    
    # ë°©í–¥ ë²¡í„° íšŒì „ (ìœ„ì¹˜ ì´ë™ ì œì™¸, íšŒì „ë§Œ)
    R_mat, _ = cv2.Rodrigues(magnet_pose[3:]) 
    dir_world = R_mat @ local_direction
    dir_world = dir_world / np.linalg.norm(dir_world) # ì •ê·œí™”
    
    # 2D í‰ë©´(XY) íˆ¬ì˜
    start_pt = p_measure_world[:2]     # (x, y)
    measure_dir = dir_world[:2]        # (dx, dy)
    measure_dir /= np.linalg.norm(measure_dir)

    # 4. ì² íŒì˜ íƒ€ê²Ÿ ë³€(Top Edge) ì°¾ê¸°
    # ì² íŒ ì½”ë„ˆ 4ê°œ ì¤‘ 'ê°€ì¥ ìœ„ìª½'ì— ìˆëŠ” ë‘ ì ì„ ì°¾ì•„ì•¼ í•¨.
    # (ì¸¡ì • ë°©í–¥ê³¼ ê°€ì¥ ë©€ë¦¬ ìˆëŠ” ì ë“¤, í˜¹ì€ Yê°’ì´ ê°€ì¥ ì‘ì€ ì ë“¤)
    # ì¸¡ì • ë°©í–¥(ìœ„ìª½)ê³¼ ë‚´ì (Dot Product)ì´ ê°€ì¥ í° ë‘ ì ì„ ì°¾ìŒ.
    
    slab_center = np.mean(slab_corners_3d[:, :2], axis=0)
    dots = np.dot(slab_corners_3d[:, :2] - slab_center, measure_dir)
    
    # ë‚´ì ê°’ì´ í° ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ë°©í–¥ê³¼ ì¼ì¹˜í•˜ëŠ” ìª½)
    target_idx = np.argsort(dots)[-2:] 
    
    edge_p1 = slab_corners_3d[target_idx[0], :2]
    edge_p2 = slab_corners_3d[target_idx[1], :2]
    
    # 5. ë¶€í˜¸ ìˆëŠ” ê±°ë¦¬ ê³„ì‚° (Signed Distance)
    # ì (Start_pt)ì—ì„œ ì§ì„ (Edge_p1-p2)ê¹Œì§€ì˜ ê±°ë¦¬
    # ê³µì‹: distance = ( (x2-x1)(y1-y0) - (x1-x0)(y2-y1) ) / sqrt(...)
    # í˜¹ì€ ë²¡í„° íˆ¬ì˜ ë°©ì‹ ì‚¬ìš©
    
    # ì§ì„ ì˜ ë²•ì„  ë²¡í„° (Edge Normal) êµ¬í•˜ê¸°
    edge_vec = edge_p2 - edge_p1
    edge_len = np.linalg.norm(edge_vec)
    if edge_len < 1e-6: return 0.0, (start_pt, start_pt)
    
    # ì§ì„ ì˜ í•œ ì (P1)ê³¼ ì¸¡ì •ì (P0) ë²¡í„°
    vec_p0_to_line = edge_p1 - start_pt
    
    # ì¸¡ì • ë°©í–¥(measure_dir)ìœ¼ë¡œì˜ ê±°ë¦¬ ì„±ë¶„ ì¶”ì¶œ
    # ì¸¡ì • ë°©í–¥ê³¼ í‰í–‰í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 'ì§ì„ ê¹Œì§€ì˜ ìµœë‹¨ ê±°ë¦¬'ê°€ ì•„ë‹ˆë¼
    # 'ì¸¡ì • ë°©í–¥ ì§ì„ 'ê³¼ 'ì² íŒ ì—£ì§€ ì§ì„ 'ì˜ êµì ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ êµ¬í•´ì•¼ í•¨ (Ray Casting)
    
    # Ray: P = S + t * D
    # Line: Q = P1 + u * (P2 - P1)
    # êµì  T êµ¬í•˜ê¸° (ì´ì „ì— ì“´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
    
    def get_signed_distance_ray(start, direction, p1, p2):
        x1, y1 = start
        dx, dy = direction
        x3, y3 = p1
        x4, y4 = p2
        
        denom = dx * (y3 - y4) - dy * (x3 - x4)
        if abs(denom) < 1e-6: return 0.0 # í‰í–‰
        
        # t: startë¡œë¶€í„° êµì ê¹Œì§€ì˜ ê±°ë¦¬ (ë°©í–¥ í¬í•¨)
        t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom
        return t

    dist_signed = get_signed_distance_ray(start_pt, measure_dir, edge_p1, edge_p2)
    
    # ë‹¨ìœ„ ë³€í™˜ (m -> mm)
    return dist_signed * 1000.0, (start_pt, measure_dir)

# ========================================
# 10. Open3D ì‹œê°í™” í†µí•© í•¨ìˆ˜
# ========================================
def visualize_full_3d(
    pcd_lidar=None, T_l2c=None, mask_obj1=None, mask_obj2=None, 
    K=None, dist_coeffs=None, W=None, H=None, max_depth=9.2, 
    estimated_box=None, estimated_wireframe=None,obj2_rbox_corners=None,
    icp_generated_points=None,
    target_model_points=None,
    obj1_plane_mesh=None
):
    """
    LiDAR, ì¶”ì • Box, í‰ë©´ Meshë¥¼ ëª¨ë‘ í†µí•©í•˜ì—¬ ì‹œê°í™”
    """
    vis_geometries = []
    obj2_pts_cam = None 

    # ------------------------------------------------------------------
    # 1) LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì²˜ë¦¬ (ìƒ‰ì¹ )
    # ------------------------------------------------------------------
    if pcd_lidar is not None and T_l2c is not None:
        pts_l = np.asarray(pcd_lidar.points, dtype=np.float32)
        if pts_l.size > 0:
            pts_h = np.hstack([pts_l, np.ones((len(pts_l), 1), dtype=np.float32)])
            pts_cam = (T_l2c @ pts_h.T).T[:, :3]
            Z = pts_cam[:, 2]
            depth_mask = (Z > 1e-6) & (Z < max_depth)
            pts_cam_filtered = pts_cam[depth_mask]
            Nf = pts_cam_filtered.shape[0]
            colors = np.full((Nf, 3), [0.7, 0.7, 0.7], dtype=np.float32)
            
            if all(p is not None for p in [K, dist_coeffs, W, H]) and Nf > 0:
                # filter_points_by_mask í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Obj1, Obj2 í¬ì¸íŠ¸ ì¶”ì¶œ
                obj1_pts_cam = filter_points_by_mask(pts_cam_filtered, mask_obj1, K, dist_coeffs, W, H) if mask_obj1 is not None else np.array([])
                obj2_pts_cam = filter_points_by_mask(pts_cam_filtered, mask_obj2, K, dist_coeffs, W, H) if mask_obj2 is not None else np.array([])
                
                # ê° í¬ì¸íŠ¸ê°€ ì–´ëŠ ë§ˆìŠ¤í¬ì— ì†í•˜ëŠ”ì§€ ìƒ‰ìƒ í• ë‹¹
                for i, pt in enumerate(pts_cam_filtered):
                    # Obj1ì— ì†í•˜ëŠ”ì§€ í™•ì¸
                    if len(obj1_pts_cam) > 0 and np.any(np.all(np.isclose(obj1_pts_cam, pt, atol=1e-6), axis=1)):
                        colors[i] = [1.0, 0.5, 0.0]  # ğŸŸ  Obj1: ì£¼í™©ìƒ‰
                    # Obj2ì— ì†í•˜ëŠ”ì§€ í™•ì¸
                    elif len(obj2_pts_cam) > 0 and np.any(np.all(np.isclose(obj2_pts_cam, pt, atol=1e-6), axis=1)):
                        colors[i] = [0.5, 1.0, 0.0]  # ğŸŸ¢ Obj2: ì—°ë‘ìƒ‰

            pcd_vis = o3d.geometry.PointCloud()
            pcd_vis.points = o3d.utility.Vector3dVector(pts_cam_filtered.astype(np.float64))
            pcd_vis.colors = o3d.utility.Vector3dVector(colors.astype(np.float64))
            vis_geometries.append(pcd_vis)

            # ----------------------------------------------------------
            # 2) Obj2 í‰ë©´ í”¼íŒ… ë° R-Box ë©”ì‰¬ ìƒì„± (Obj2ê°€ ì¡´ì¬í•  ë•Œ)
            # ----------------------------------------------------------
            if (obj2_pts_cam is not None and obj2_pts_cam.shape[0] >= 3 and 
                obj2_rbox_corners is not None):
                
                
                normal, d, centroid, inlier_mask = two_stage_plane_fit(obj2_pts_cam)

                if normal is not None:
                    inlier_pts = obj2_pts_cam[inlier_mask]
                    if inlier_pts.shape[0] >= 3: centroid = inlier_pts.mean(axis=0)
                    
                    plane_mesh = build_rbox_clipped_plane(
                        obj2_rbox_corners, normal, centroid, K=K, dist_coeffs=dist_coeffs, color=(0.0, 0.3, 0.5)
                    )
                    if plane_mesh: vis_geometries.append(plane_mesh)

    # ------------------------------------------------------------------
    # 3) Estimated Box (Mesh) ì¶”ê°€
    # ------------------------------------------------------------------
    if estimated_box is not None:
        vis_geometries.append(estimated_box)
    if estimated_wireframe is not None:
        vis_geometries.append(estimated_wireframe)
    
    # Obj1 í‰ë©´ ë©”ì‰¬ ì¶”ê°€
    if obj1_plane_mesh is not None:
        vis_geometries.append(obj1_plane_mesh)
    
    if icp_generated_points is not None and len(icp_generated_points) > 0:
        pcd_icp = o3d.geometry.PointCloud()
        pcd_icp.points = o3d.utility.Vector3dVector(icp_generated_points.astype(np.float64))
        pcd_icp.paint_uniform_color([1.0, 0.0, 1.0]) # ìí™ìƒ‰
        vis_geometries.append(pcd_icp)
    if target_model_points is not None and len(target_model_points) > 0:
        pcd_target = o3d.geometry.PointCloud()
        pcd_target.points = o3d.utility.Vector3dVector(target_model_points.astype(np.float64))
        pcd_target.paint_uniform_color([0.0, 1.0, 1.0]) # ì²­ë¡ìƒ‰
        vis_geometries.append(pcd_target)    
    # 4) ì¢Œí‘œì¶• ë° ì‹œê°í™” ì‹¤í–‰
    vis_geometries.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=1.0))
    
    if vis_geometries:
        show_geometries_with_backface(vis_geometries, title="Full 3D Visualization (Pose + LiDAR)")

TARGET_DPI = 100

def initialize_sam2_and_prompts():
    """DZ íŒŒì‹± + Obj1/Obj2 í”„ë¡¬í”„íŠ¸ êµ¬ì„± + SAM2 state ì´ˆê¸°í™” + íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    print("\n" + "="*50)
    print("Initializing SAM2 inference state...")
    print("="*50)

    print("\n" + "="*50)
    print("Generating automatic prompts from DZ value...")
    print("="*50)

    # DZ ê°’ íŒŒì‹±
    acwl_dz = parse_dz_from_results(Config.RESULTS_DIR, frame_idx=0)
    if acwl_dz is None:
        print("   âš ï¸ DZ not found in results, using default 972mm")
        acwl_dz = 972

    # Config ì—…ë°ì´íŠ¸
    Config.ACWL_DZ = acwl_dz
    Config.DEPTH_TH = 10 - (acwl_dz * 0.001) + 0.3

    # Obj1 ìë™ í”„ë¡¬í”„íŠ¸
    Config.OBJ_1_POINTS = get_prompt_points_from_dz(acwl_dz)
    print(f"   ğŸ¯ Auto-generated OBJ_1 prompts from DZ={acwl_dz}mm:")
    print(f"      Point 1: ({Config.OBJ_1_POINTS[0][0]:.1f}, {Config.OBJ_1_POINTS[0][1]:.1f})")
    print(f"      Point 2: ({Config.OBJ_1_POINTS[1][0]:.1f}, {Config.OBJ_1_POINTS[1][1]:.1f})")
    print(f"      Point 3: ({Config.OBJ_1_POINTS[2][0]:.1f}, {Config.OBJ_1_POINTS[2][1]:.1f})")

    # Obj2 í”„ë¡¬í”„íŠ¸ (ML)
    print(f"\n   ğŸ¤– Predicting OBJ_2 prompts using ML model...")
    obj2_predicted = predict_obj2_prompts(Config.ID, n_points=N_POINTS_OBJ2)

    if obj2_predicted is not None:
        print(f"   âœ… ML prediction successful ({len(obj2_predicted)} points):")
        for i, pt in enumerate(obj2_predicted, 1):
            print(f"      Point {i}: ({pt[0]:.1f}, {pt[1]:.1f})")
        obj2_positive_points = obj2_predicted
    else:
        print(f"   âš ï¸ ML prediction failed, using default fixed prompts")
        obj2_positive_points = Config.OBJ_2_POINTS

    # Obj1ì„ Obj2ì˜ negative í”„ë¡¬í”„íŠ¸ë¡œ ì¶”ê°€
    obj2_negative_points = Config.OBJ_1_POINTS
    Config.OBJ_2_POINTS = np.vstack([obj2_positive_points, obj2_negative_points])
    Config.OBJ_2_LABELS = np.array(
        [1] * len(obj2_positive_points) + [0] * len(obj2_negative_points),
        dtype=np.int32
    )

    print(f"   ğŸ¯ Final OBJ_2 prompts (including OBJ_1 as negative):")
    print(f"      Positive: {len([l for l in Config.OBJ_2_LABELS if l == 1])} points")
    print(f"      Negative: {len([l for l in Config.OBJ_2_LABELS if l == 0])} points (includes OBJ_1)")

    # SAM2 state ì´ˆê¸°í™”
    inference_state = predictor.init_state(video_path=Config.VIDEO_DIR)
    predictor.reset_state(inference_state)

    # Obj1, Obj2 í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    obj_id_1 = 1
    obj_id_2 = 2

    predictor.add_new_points_or_box(
        inference_state=inference_state, frame_idx=0,
        obj_id=obj_id_1,
        points=Config.OBJ_1_POINTS, labels=Config.OBJ_1_LABELS
    )
    predictor.add_new_points_or_box(
        inference_state=inference_state, frame_idx=0,
        obj_id=obj_id_2,
        points=Config.OBJ_2_POINTS, labels=Config.OBJ_2_LABELS
    )

    # íŒŒì¼ ëª©ë¡
    frame_names = sorted([
        p for p in os.listdir(Config.VIDEO_DIR)
        if p.endswith(('.jpg', '.jpeg'))
    ])
    pcd_files = sorted([
        p for p in os.listdir(Config.PCD_DIR)
        if p.endswith('.pcd')
    ])

    return inference_state, frame_names, pcd_files, obj_id_1, obj_id_2


def build_video_segments(inference_state):
    """SAM2 propagate_in_video ê²°ê³¼ë¥¼ video_segments ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì„±"""
    video_segments = {}
    for f_idx, obj_ids, mask_logits in predictor.propagate_in_video(inference_state):
        video_segments[f_idx] = {
            oid: to_bool_mask((mask_logits[i] > 0.0).cpu().numpy())
            for i, oid in enumerate(obj_ids.tolist() if hasattr(obj_ids, "tolist") else obj_ids)
        }
    return video_segments


def compute_and_draw_measurements(
    ax,
    f_idx,
    final_vertices,
    slab_corners_3d,
    normal_obj2,
    centroid_obj2,
    T_icp_final,
    estimated_param
):
    """
    - ë§ˆê·¸ë„· ë°•ìŠ¤(final_vertices)ì™€ ì² íŒ ì½”ë„ˆ(slab_corners_3d)ë¥¼ ì´ìš©í•´
      P1-P2, P3-P4, P5-P6, P7-P8 ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ê³ 
      ì´ë¯¸ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í™”ì‚´í‘œ ë° í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦°ë‹¤.
    - ì¸¡ì • ê²°ê³¼ dictë¥¼ ë°˜í™˜í•œë‹¤.
    """
    # ========== ì¤€ë¹„ ==========
    # ìŠ¬ë˜ë¸Œ ì¤‘ì‹¬
    slab_center = np.mean(slab_corners_3d[:, :2], axis=0)

    # ìµœì¢… ë°•ìŠ¤ ê¼­ì§“ì  (ì´ë¦„ë§Œ ì •ë¦¬)
    top_left_corner    = final_vertices[0]  # TL
    bottom_left_corner = final_vertices[1]  # BL

    # ë§ˆê·¸ë„· ê¸¸ì´ ë°©í–¥ param (0~MAGNET_LENGTH)
    t1 = 0.7 / MAGNET_LENGTH
    t2 = (MAGNET_LENGTH - 0.7) / MAGNET_LENGTH

    # ê¸¸ì´ ì¸¡ì • ì‹œì‘ì  (3D)
    measure_pt_top = top_left_corner + t1 * (bottom_left_corner - top_left_corner)
    measure_pt_bot = top_left_corner + t2 * (bottom_left_corner - top_left_corner)

    # íšŒì „ í–‰ë ¬ (Yaw + ICP)
    yaw = estimated_param[2]
    R_theta = np.array([
        [np.cos(yaw), -np.sin(yaw), 0],
        [np.sin(yaw),  np.cos(yaw), 0],
        [0, 0, 1]
    ])
    R_icp = T_icp_final[:3, :3]
    R_total = R_icp @ R_theta

    # ê¸¸ì´ ë°©í–¥: ë¡œì»¬ xì¶• â†’ ì›”ë“œ
    dir_world = R_total @ np.array([1.0, 0.0, 0.0])
    measure_dir_2d = dir_world[:2]
    measure_dir_2d /= (np.linalg.norm(measure_dir_2d) + 1e-12)

    # ë³´ì¡° í•¨ìˆ˜: ray-line ê±°ë¦¬
    def ray_line_dist(start_pt, direction, p1, p2):
        x1, y1 = start_pt
        dx, dy = direction
        x3, y3 = p1
        x4, y4 = p2
        denom = dx * (y3 - y4) - dy * (x3 - x4)
        if abs(denom) < 1e-6:
            return 0.0
        t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom
        return abs(t)

    # ========== ê¸¸ì´ ì¸¡ì • ì—£ì§€ ì„ íƒ ==========
    dots = np.dot(slab_corners_3d[:, :2] - slab_center, measure_dir_2d)
    target_idx = np.argsort(dots)[-2:]
    edge_p1 = slab_corners_3d[target_idx[0], :2]
    edge_p2 = slab_corners_3d[target_idx[1], :2]

    # ê¸¸ì´(ìœ„/ì•„ë˜) ê³„ì‚°
    len_top_mm = ray_line_dist(measure_pt_top[:2], measure_dir_2d, edge_p1, edge_p2) * 1000.0
    len_bot_mm = ray_line_dist(measure_pt_bot[:2], measure_dir_2d, edge_p1, edge_p2) * 1000.0

    # ========== ë„ˆë¹„ ì¸¡ì • (ìœ—ë³€) ==========
    width_dir_world = R_total @ np.array([0.0, -1.0, 0.0])  # ë¡œì»¬ -y
    width_dir_2d = width_dir_world[:2]
    width_dir_2d /= (np.linalg.norm(width_dir_2d) + 1e-12)

    dots_width = np.dot(slab_corners_3d[:, :2] - slab_center, width_dir_2d)
    target_idx_width = np.argsort(dots_width)[-2:]
    edge_w1 = slab_corners_3d[target_idx_width[0], :2]
    edge_w2 = slab_corners_3d[target_idx_width[1], :2]

    width_dist = ray_line_dist(top_left_corner[:2], width_dir_2d, edge_w1, edge_w2)
    width_mm = width_dist * 1000.0

    # ========== ë„ˆë¹„ ì¸¡ì • (ì•„ë«ë³€) ==========
    width_bottom_dir_world = R_total @ np.array([0.0, 1.0, 0.0])  # ë¡œì»¬ +y
    width_bottom_dir_2d = width_bottom_dir_world[:2]
    width_bottom_dir_2d /= (np.linalg.norm(width_bottom_dir_2d) + 1e-12)

    dots_width_bottom = np.dot(slab_corners_3d[:, :2] - slab_center, width_bottom_dir_2d)
    target_idx_width_bottom = np.argsort(dots_width_bottom)[-2:]
    edge_wb1 = slab_corners_3d[target_idx_width_bottom[0], :2]
    edge_wb2 = slab_corners_3d[target_idx_width_bottom[1], :2]

    width_bottom_dist = ray_line_dist(bottom_left_corner[:2], width_bottom_dir_2d, edge_wb1, edge_wb2)
    width_bottom_mm = width_bottom_dist * 1000.0

    print(f"   ğŸ“ Length Top: {len_top_mm:.1f}mm, Bottom: {len_bot_mm:.1f}mm")
    print(f"   ğŸ“ Width Top: {width_mm:.1f}mm, Bottom: {width_bottom_mm:.1f}mm")

    # ========== 3D â†’ 2D íˆ¬ì˜ í›„ í™”ì‚´í‘œ/í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° ==========
    # ëì  3D ê³„ì‚°
    end_pt_top_3d  = measure_pt_top  + dir_world * (len_top_mm / 1000.0)
    end_pt_bot_3d  = measure_pt_bot  + dir_world * (len_bot_mm / 1000.0)
    end_pt_width_3d        = top_left_corner    + width_dir_world        * (width_mm / 1000.0)
    end_pt_width_bottom_3d = bottom_left_corner + width_bottom_dir_world * (width_bottom_mm / 1000.0)

    pts_to_project = np.array([
        measure_pt_top,          # 0
        measure_pt_bot,          # 1
        top_left_corner,         # 2
        bottom_left_corner,      # 3
        end_pt_top_3d,           # 4
        end_pt_bot_3d,           # 5
        end_pt_width_3d,         # 6
        end_pt_width_bottom_3d   # 7
    ])

    img_measure_pts, _ = cv2.projectPoints(
        pts_to_project, np.zeros(3), np.zeros(3), K_camera, D_dist
    )
    img_measure_pts = img_measure_pts.reshape(-1, 2)

    p_start_top          = img_measure_pts[0]
    p_start_bot          = img_measure_pts[1]
    p_start_width        = img_measure_pts[2]
    p_start_width_bottom = img_measure_pts[3]

    p_end_top          = img_measure_pts[4]
    p_end_bot          = img_measure_pts[5]
    p_end_width        = img_measure_pts[6]
    p_end_width_bottom = img_measure_pts[7]

    # ê¸¸ì´ ìœ„ìª½ (ë…¸ë€ìƒ‰)
    ax.plot(p_start_top[0], p_start_top[1], 'o', color='yellow', markersize=6, markeredgecolor='black')
    ax.plot(p_end_top[0],   p_end_top[1],   'x', color='yellow', markersize=6, markeredgecolor='black')
    ax.annotate('', xy=p_end_top, xytext=p_start_top,
                arrowprops=dict(arrowstyle='->', color='yellow', lw=2, shrinkA=0, shrinkB=0))
    mid_top = (p_start_top + p_end_top) / 2
    ax.text(
        mid_top[0], mid_top[1] - 15, f'{len_top_mm:.0f}mm',
        color='yellow', fontsize=9, weight='bold', ha='center',
        bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.6)
    )

    # ê¸¸ì´ ì•„ë˜ìª½ (ì‹œì•ˆìƒ‰)
    ax.plot(p_start_bot[0], p_start_bot[1], 'o', color='cyan', markersize=6, markeredgecolor='black')
    ax.plot(p_end_bot[0],   p_end_bot[1],   'x', color='cyan', markersize=6, markeredgecolor='black')
    ax.annotate('', xy=p_end_bot, xytext=p_start_bot,
                arrowprops=dict(arrowstyle='->', color='cyan', lw=2, shrinkA=0, shrinkB=0))
    mid_bot = (p_start_bot + p_end_bot) / 2
    ax.text(
        mid_bot[0], mid_bot[1] + 20, f'{len_bot_mm:.0f}mm',
        color='cyan', fontsize=9, weight='bold', ha='center',
        bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.6)
    )

    # ë„ˆë¹„ ìœ„ìª½ (ë§ˆì  íƒ€)
    ax.plot(p_start_width[0], p_start_width[1], 'o', color='magenta', markersize=6, markeredgecolor='black')
    ax.plot(p_end_width[0],   p_end_width[1],   'x', color='magenta', markersize=6, markeredgecolor='black')
    ax.annotate('', xy=p_end_width, xytext=p_start_width,
                arrowprops=dict(arrowstyle='->', color='magenta', lw=2, shrinkA=0, shrinkB=0))
    mid_width = (p_start_width + p_end_width) / 2
    ax.text(
        mid_width[0] - 40, mid_width[1], f'{width_mm:.0f}mm',
        color='magenta', fontsize=9, weight='bold', ha='right',
        bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.6)
    )

    # ë„ˆë¹„ ì•„ë˜ìª½ (ë¼ì„)
    ax.plot(p_start_width_bottom[0], p_start_width_bottom[1], 'o', color='lime', markersize=6, markeredgecolor='black')
    ax.plot(p_end_width_bottom[0],   p_end_width_bottom[1],   'x', color='lime', markersize=6, markeredgecolor='black')
    ax.annotate('', xy=p_end_width_bottom, xytext=p_start_width_bottom,
                arrowprops=dict(arrowstyle='->', color='lime', lw=2, shrinkA=0, shrinkB=0))
    mid_width_bottom = (p_start_width_bottom + p_end_width_bottom) / 2
    ax.text(
        mid_width_bottom[0] - 40, mid_width_bottom[1], f'{width_bottom_mm:.0f}mm',
        color='lime', fontsize=9, weight='bold', ha='right',
        bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.6)
    )

    # CSVìš© ë ˆì½”ë“œ ë°˜í™˜
    measurement_record = {
        'frame': f_idx,
        'P1-P2': len_top_mm,
        'P3-P4': len_bot_mm,
        'P5-P6': width_mm,
        'P7-P8': width_bottom_mm
    }
    return measurement_record


def process_single_frame(
    f_idx,
    fname,
    pcd_files,
    video_segments,
    obj_id_1,
    obj_id_2,
    last_successful_pose
):
    img_path = os.path.join(Config.VIDEO_DIR, fname)
    pcd_path = os.path.join(Config.PCD_DIR, pcd_files[f_idx]) if f_idx < len(pcd_files) else None

    img = Image.open(img_path).convert("RGB")
    W, H = img.size

    fig_w_inch = W / TARGET_DPI
    fig_h_inch = H / TARGET_DPI
    fig = plt.figure(figsize=(fig_w_inch, fig_h_inch))
    ax = plt.gca()
    ax.imshow(img)
    ax.set_title(f"Frame {f_idx} : Matrix Transform Vis")
    ax.set_xlim([0, W])
    ax.set_ylim([H, 0])
    ax.set_axis_off()

    masks = video_segments.get(f_idx, {})
    mask_obj1 = masks.get(obj_id_1, None)
    mask_obj2 = masks.get(obj_id_2, None)

    estimated_param = None
    obj1_corners = None
    obj2_rbox_corners = None

    # 1. ë§ˆìŠ¤í¬ ë° RBox ì¶”ì¶œ
    for oid in [obj_id_1, obj_id_2]:
        mask = masks.get(oid)
        if mask is not None:
            edge = "orange" if oid == obj_id_1 else "deepskyblue"
            draw_mask_and_rbox(
                ax, mask, oid, edge, H, W,
                Config.APPLY_EROSION, Config.EROSION_KERNEL_SIZE, Config.EROSION_ITERATIONS
            )
            mask_eroded = apply_erosion(mask, Config.EROSION_KERNEL_SIZE, Config.EROSION_ITERATIONS) if Config.APPLY_EROSION else mask
            corners, *_ = mask_to_rotated_box(mask_eroded)

            if corners is not None:
                if oid == obj_id_1:
                    obj1_corners = corners
                elif oid == obj_id_2:
                    obj2_rbox_corners = corners

    final_box_mesh = None
    final_wireframe = None
    final_icp_points = None
    P_target_icp = None
    obj1_plane_mesh = None
    T_icp_final = np.identity(4)

    measurement_record = None

    if obj1_corners is not None:
        ordered_corners = order_points_for_model(obj1_corners)
        initial_param = last_successful_pose.copy()

        try:
            # 2-1. LS Pose
            res = least_squares(
                cost_function, initial_param,
                args=(model_points_3d_top, ordered_corners, K_camera, D_dist),
                loss='soft_l1'
            )
            estimated_param = res.x
            last_successful_pose = estimated_param.copy()

            T_icp_final = np.identity(4)
            synthetic_plane_cloud = None
            obj2_pts_cam = None
            normal_obj2 = None
            centroid_obj2 = None

            # 2-2. Obj2 í¬ì¸íŠ¸ + í•„í„°ë§
            if pcd_path and os.path.exists(pcd_path) and mask_obj2 is not None:
                pcd = o3d.io.read_point_cloud(pcd_path)
                pts_l = np.asarray(pcd.points, dtype=np.float32)
                pts_h = np.hstack([pts_l, np.ones((len(pts_l), 1), dtype=np.float32)])

                P_full_cam = (T_l2c @ pts_h.T).T[:, :3]
                obj2_pts_cam, mask_obj2_updated = filter_points_by_mask(
                    P_full_cam, mask_obj2, K_camera, D_dist, W, H,
                    depth_threshold=Config.DEPTH_TH, update_mask=True
                )
                print(f"   ğŸ” Obj2 filtered: {len(obj2_pts_cam)} points (depth < {Config.DEPTH_TH}m)")

                if mask_obj2_updated is not None:
                    mask_obj2 = mask_obj2_updated
                    draw_mask_and_rbox(
                        ax, mask_obj2, obj_id_2, "deepskyblue", H, W,
                        Config.APPLY_EROSION, Config.EROSION_KERNEL_SIZE, Config.EROSION_ITERATIONS
                    )
                    mask_eroded_obj2 = apply_erosion(mask_obj2, Config.EROSION_KERNEL_SIZE, Config.EROSION_ITERATIONS) if Config.APPLY_EROSION else mask_obj2
                    corners_updated, *_ = mask_to_rotated_box(mask_eroded_obj2)
                    if corners_updated is not None:
                        obj2_rbox_corners = corners_updated
                        print(f"   ğŸ”„ Obj2 rbox updated with filtered mask")

            # 2-3. Obj2 í‰ë©´ + ICP
            if obj2_rbox_corners is not None and obj2_pts_cam is not None and len(obj2_pts_cam) > 10:
                normal_obj2, _, centroid_obj2, inlier_mask_obj2 = two_stage_plane_fit(obj2_pts_cam)

                if normal_obj2 is not None:
                    inlier_pts_obj2 = obj2_pts_cam[inlier_mask_obj2]
                    if len(inlier_pts_obj2) > 3:
                        centroid_obj2 = inlier_pts_obj2.mean(axis=0)

                    synthetic_plane_cloud = generate_synthetic_plane_cloud(
                        obj2_rbox_corners, normal_obj2, centroid_obj2, K_camera, D_dist
                    )
                    obj1_bottom_cloud = get_obj1_bottom_cloud(estimated_param)

                    if synthetic_plane_cloud is not None and len(synthetic_plane_cloud) > 10:
                        print(f"   ğŸ”Œ Aligning Obj1 Bottom to Obj2 Plane (Target Pts: {len(synthetic_plane_cloud)})")
                        T_icp_final = refine_pose_icp_constrained(
                            obj1_bottom_cloud, synthetic_plane_cloud, max_iteration=30
                        )
                        print(f"   âœ… ICP Constrained Result:\n{T_icp_final}")
                        delta_t = np.linalg.norm(T_icp_final[:3, 3])
                        if delta_t > 1.0:
                            print(f"   âš ï¸ ICP Delta too large ({delta_t:.2f}m). Ignored.")
                            T_icp_final = np.identity(4)

            # 2-4. Box Mesh
            base_mesh, base_wire = get_3d_box_mesh(estimated_param, color=[1, 0, 0])
            base_mesh.transform(T_icp_final)
            base_wire.transform(T_icp_final)
            final_box_mesh = base_mesh
            final_wireframe = base_wire

            if synthetic_plane_cloud is not None:
                final_icp_points = synthetic_plane_cloud

            # 3. ì¸¡ì •/ê·¸ë¦¬ê¸° (ë¶„ë¦¬ëœ í•¨ìˆ˜ í˜¸ì¶œ)
            if (
                obj2_rbox_corners is not None
                and len(obj2_rbox_corners) == 4
                and normal_obj2 is not None
                and centroid_obj2 is not None
            ):
                # ìŠ¬ë˜ë¸Œ ì½”ë„ˆ 3D ë³µì›
                uv_pts = np.asarray(obj2_rbox_corners, dtype=np.float32).reshape(-1, 1, 2)
                xy_undist = cv2.undistortPoints(uv_pts, K_camera, D_dist).squeeze()

                slab_corners_3d = []
                n = np.asarray(normal_obj2, dtype=np.float32)
                n = n / (np.linalg.norm(n) + 1e-12)
                p0 = np.asarray(centroid_obj2, dtype=np.float32)

                for x_n, y_n in xy_undist:
                    d_ray = np.array([x_n, y_n, 1.0], dtype=np.float32)
                    d_ray = d_ray / np.linalg.norm(d_ray)
                    denom = float(np.dot(n, d_ray))
                    if abs(denom) < 1e-6:
                        continue
                    t = float(np.dot(n, p0) / denom)
                    if t <= 0:
                        continue
                    P = d_ray * t
                    slab_corners_3d.append(P)

                if len(slab_corners_3d) == 4:
                    slab_corners_3d = np.array(slab_corners_3d)
                    measurement_record = compute_and_draw_measurements(
                        ax,
                        f_idx,
                        np.asarray(final_box_mesh.vertices),
                        slab_corners_3d,
                        normal_obj2,
                        centroid_obj2,
                        T_icp_final,
                        estimated_param
                    )

            # 4. 2D ë°•ìŠ¤ ì™€ì´ì–´í”„ë ˆì„
            if final_box_mesh is not None:
                tx_verts = np.asarray(final_box_mesh.vertices)
                img_pts, _ = cv2.projectPoints(tx_verts, np.zeros(3), np.zeros(3), K_camera, D_dist)
                img_pts = img_pts.reshape(-1, 2).astype(int)
                lines = [
                    [0,1],[1,2],[2,3],[3,0],
                    [4,5],[5,6],[6,7],[7,4],
                    [0,4],[1,5],[2,6],[3,7]
                ]
                for s, e in lines:
                    ax.plot(
                        [img_pts[s, 0], img_pts[e, 0]],
                        [img_pts[s, 1], img_pts[e, 1]],
                        color='red', linewidth=1.5
                    )

            # 5. Pose í…ìŠ¤íŠ¸
            if estimated_param is not None:
                tx, ty, yaw, z = estimated_param
                pose_text = (
                    f"6DOF Pose:\n"
                    f"Trans: ({tx:.2f}, {ty:.2f}, {z:.2f})m\n"
                    f"Rot: ({np.degrees(yaw):.1f})Â°\n"
                )
                if measurement_record is not None:
                    pose_text += (
                        f"Length: T={measurement_record['P1-P2']:.1f}mm "
                        f"B={measurement_record['P3-P4']:.1f}mm\n"
                        f"Width: T={measurement_record['P5-P6']:.1f}mm "
                        f"B={measurement_record['P7-P8']:.1f}mm"
                    )
                ax.text(
                    20, 40, pose_text,
                    color='white', fontsize=10,
                    bbox=dict(facecolor='black', alpha=0.5)
                )

        except Exception as e:
            print(f"âŒ Error frame {f_idx}: {e}")
            traceback.print_exc()

    # 6. ì´ë¯¸ì§€ ì €ì¥
    out_path = os.path.join(Config.OUTPUT_DIR, f"frame_{f_idx:05d}.jpg")
    plt.savefig(out_path, dpi=TARGET_DPI, bbox_inches='tight', pad_inches=0)
    plt.close(fig)

    # 7. Open3D ì‹œê°í™”
    if Config.SHOW_O3D and pcd_path and os.path.exists(pcd_path):
        pcd = o3d.io.read_point_cloud(pcd_path)
        visualize_full_3d(
            pcd_lidar=pcd, T_l2c=T_l2c,
            mask_obj1=mask_obj1, mask_obj2=mask_obj2,
            K=K_camera, dist_coeffs=D_dist, W=W, H=H,
            max_depth=Config.MAX_DEPTH,
            estimated_box=final_box_mesh,
            estimated_wireframe=final_wireframe,
            obj2_rbox_corners=obj2_rbox_corners,
            icp_generated_points=final_icp_points,
            target_model_points=P_target_icp,
            obj1_plane_mesh=obj1_plane_mesh
        )

    return last_successful_pose, measurement_record



def process_all_frames(frame_names, pcd_files, video_segments, obj_id_1, obj_id_2):
    """ì „ì²´ í”„ë ˆì„ ë£¨í”„ë¥¼ ëŒë©´ì„œ ì¸¡ì •ê°’ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±"""
    last_successful_pose = np.array([0.0, 0.0, 0.0, 0.0])
    measurement_records = []

    for f_idx, fname in enumerate(frame_names):
        last_successful_pose, record = process_single_frame(
            f_idx, fname, pcd_files, video_segments,
            obj_id_1, obj_id_2, last_successful_pose
        )
        if record is not None:
            measurement_records.append(record)

    return measurement_records


def save_measurements_csv(measurement_records):
    """ì¸¡ì •ê°’ CSV ë° í‰ê· í–‰ ì €ì¥"""
    if len(measurement_records) == 0:
        print("\nâš ï¸ No measurements recorded.")
        return

    csv_path = os.path.join(Config.OUTPUT_DIR, "measurements.csv")

    with open(csv_path, 'w', newline='') as csvfile:
        fieldnames = ['frame', 'P1-P2', 'P3-P4', 'P5-P6', 'P7-P8']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        for record in measurement_records:
            writer.writerow(record)

        if len(measurement_records) > 1:
            records_for_avg = measurement_records[1:]
            avg_len_top = np.mean([r['P1-P2'] for r in records_for_avg])
            avg_len_bot = np.mean([r['P3-P4'] for r in records_for_avg])
            avg_width_top = np.mean([r['P5-P6'] for r in records_for_avg])
            avg_width_bot = np.mean([r['P7-P8'] for r in records_for_avg])

            writer.writerow({
                'frame': 'AVERAGE',
                'P1-P2': f"{avg_len_top:.6f}",
                'P3-P4': f"{avg_len_bot:.6f}",
                'P5-P6': f"{avg_width_top:.6f}",
                'P7-P8': f"{avg_width_bot:.6f}"
            })

    print(f"\nğŸ“Š Measurements saved to: {csv_path}")
    print(f"   Total frames: {len(measurement_records)}")
    if len(measurement_records) > 1:
        print(f"   Average (excluding first frame) - Length Top: {avg_len_top:.6f}mm, Bottom: {avg_len_bot:.6f}mm")
        print(f"   Average (excluding first frame) - Width Top: {avg_width_top:.6f}mm, Bottom: {avg_width_bot:.6f}mm")


def main():
    # 1) SAM2 ì´ˆê¸°í™” + í”„ë¡¬í”„íŠ¸ + íŒŒì¼ ëª©ë¡
    inference_state, frame_names, pcd_files, obj_id_1, obj_id_2 = initialize_sam2_and_prompts()

    # 2) SAM2 ì „ í”„ë ˆì„ propagate
    video_segments = build_video_segments(inference_state)

    # 3) í”„ë ˆì„ë³„ ì²˜ë¦¬ ë° ì¸¡ì •
    measurement_records = process_all_frames(
        frame_names, pcd_files, video_segments, obj_id_1, obj_id_2
    )

    print("\nâœ… Processing Complete.")

    # 4) CSV ì €ì¥
    save_measurements_csv(measurement_records)


if __name__ == "__main__":
    main()